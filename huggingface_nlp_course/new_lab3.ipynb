{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB 3 Notebook\n",
    "\n",
    "Install the Transformers, Datasets, and Evaluate libraries to run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets evaluate transformers[sentencepiece]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.\n",
    "\n",
    "Processing the Data\n",
    "\n",
    "What's the code snippet that fine-tunes a pre-trained 'bert-base-uncased' model for sequence classification on the following different context:\n",
    "\n",
    "Sequences:\n",
    "1. 'The world is full of magic.'\n",
    "2. 'Exploration leads to discovery.'\n",
    "\n",
    "Additionally:\n",
    "- Padding and truncation are applied to the tokenized sequences.\n",
    "- Labels '0' are assigned to the sequences.\n",
    "- The loss is calculated and backpropagation is performed to optimize the model parameters using an optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.\n",
    "Loading data\n",
    "\n",
    "What code snippet loads the Microsoft Research Paraphrase Corpus (MRPC) dataset using the Hugging Face `datasets` library within Python?\n",
    "\n",
    "The dataset is loaded using the function `load_dataset` from the 'glue' dataset collection. The resulting dataset is stored in the variable `raw_datasets`.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.\n",
    "\n",
    "What's the code snippet that extracts and displays the first data sample from the 'test' split of the Microsoft Research Paraphrase Corpus (MRPC) dataset stored in the variable 'raw_test_dataset' obtained from the previously loaded dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. \n",
    "Preprocessing the dataset\n",
    "\n",
    "Write a code snippet that uses a tokenizer to process the sentence pairs from the 'train' split of the Microsoft Research Paraphrase Corpus (MRPC) dataset. The code should perform tokenization, enable padding, and truncation for the sentence pairs from 'sentence1' and 'sentence2'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.\n",
    "\n",
    "Complete the Python function 'tokenize_function(sample)' that utilizes a tokenizer to process sentence pairs. The function should take a 'sample' as input, which is expected to contain 'sentence1' and 'sentence2' keys. Utilize the 'tokenizer' function to perform truncation on these sentence pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.\n",
    "\n",
    "Continuing from the previous task, utilize the 'map' function from the 'datasets' library to apply the 'tokenize_function' to the entire 'raw_datasets' for the Microsoft Research Paraphrase Corpus (MRPC). The function 'tokenize_function' performs tokenization, utilizing a tokenizer on sentence pairs provided in the 'sentence1' and 'sentence2' keys within each sample. Execute this mapping operation with batching enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write your code here"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
