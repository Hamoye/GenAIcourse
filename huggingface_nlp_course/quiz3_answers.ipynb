{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions and Answers \n",
    "\n",
    "1. What is the GLUE benchmark\n",
    "   - **B) An academic benchmark for text classification tasks**\n",
    "\n",
    "2. How many pairs of sentences are there in the training set of the MRPC dataset\n",
    "   - **A) 3,668**\n",
    "\n",
    "3. What does the 'label' column in the MRPC dataset represent\n",
    "   - **D) Indicates whether sentences are paraphrases**\n",
    "\n",
    "4. Where is the MRPC dataset cached by default upon downloading using the ðŸ¤— Datasets library\n",
    "   - **A) ~/.cache/huggingface/datasets**\n",
    "\n",
    "5. What type of label corresponds to \"not_equivalent\" in the MRPC dataset\n",
    "   - **A) 0**\n",
    "\n",
    "6. What is the purpose of the ðŸ¤— Datasets library\n",
    "   - **A) Simplify downloading and caching of datasets**\n",
    "\n",
    "7. Which command retrieves the MRPC dataset from the Hub using the ðŸ¤— Datasets library\n",
    "   - **A) `load_dataset('MRPC')`**\n",
    "\n",
    "8. What does the `DatasetDict` object contain after retrieving the MRPC dataset\n",
    "   - **C) Training set, validation set, and test set**\n",
    "\n",
    "9. What type of object stores the labels in the MRPC dataset\n",
    "   - **B) ClassLabel**\n",
    "\n",
    "10. What information does examining the 'features' of the `raw_train_dataset` provide\n",
    "    - **A) Label mapping to integers**\n",
    "\n",
    "11. How does the tokenizer handle a pair of sentences, as shown in the example?\n",
    "   - **Answer: B) Combines both sentences into a single token sequence**\n",
    "\n",
    "12. What is the purpose of the `token_type_ids` when tokenizing a pair of sentences?\n",
    "   - **Answer: D) Identifies different segments within the input pair**\n",
    "\n",
    "13. How is dynamic padding advantageous during dataset preprocessing?\n",
    "   - **Answer: D) Improves training efficiency by padding as needed for each batch**\n",
    "\n",
    "14. What is the role of the `DataCollatorWithPadding` class in dataset preparation?\n",
    "   - **Answer: C) Performs padding based on the longest element in a batch**\n",
    "\n",
    "15. Why might dynamic padding cause issues when training on a TPU?\n",
    "   - **Answer: B) TPUs require fixed shapes for inputs**\n",
    "\n",
    "16. Which method in the Dataset.map() function accelerates tokenization?\n",
    "   - **Answer: A) batched=True**\n",
    "\n",
    "17. What structure does the collate function return when batching samples using the `DataCollatorWithPadding` class?\n",
    "   - **Answer: C) Dictionary of tensors**\n",
    "\n",
    "18. What information does the lengths of tensors in the batch represent?\n",
    "   - **Answer: A) The number of tokens in each sequence**\n",
    "\n",
    "19. What does the `Dataset.map()` method do when used with `batched=True`?\n",
    "   - **Answer: C) Applies a function to multiple dataset elements simultaneously**\n",
    "\n",
    "20. What is the advantage of leveraging `Dataset.map()` with a function for preprocessing?\n",
    "    - **Answer: D) Speeds up tokenization without requiring RAM storage**\n",
    "\n",
    "21. Why might the Trainer not provide information on model performance during training?\n",
    "   - **B) Trainer only prints loss information**\n",
    "\n",
    "22. What does the `predictions` field from the `predict()` method represent?\n",
    "   - **A) Logits for each element of the dataset**\n",
    "\n",
    "23. What's the primary purpose of the `compute_metrics()` function in the Trainer API?\n",
    "   - **A) Evaluating model performance during training**\n",
    "\n",
    "24. What kind of object does the `compute()` method in `evaluate.load()` return?\n",
    "   - **D) Metrics calculator object**\n",
    "\n",
    "25. How can one improve the Trainer to report evaluation metrics during training?\n",
    "   - **C) Set `evaluation_strategy` in `TrainingArguments`**\n",
    "\n",
    "26. What's the purpose of setting the `evaluation_strategy` to \"epoch\" in `TrainingArguments`?\n",
    "   - **A) Evaluates the model at every epoch**\n",
    "\n",
    "27. What's the significance of the F1 score reported in the Trainer's `compute_metrics()`?\n",
    "   - **C) It signifies the model's precision and recall**\n",
    "\n",
    "28. How can one continue training or overwrite existing checkpoints in the Trainer?\n",
    "   - **A) Use `trainer.run_continued()`**\n",
    "\n",
    "29. What does the Trainer's `fp16` argument enable?\n",
    "   - **A) Mixed-precision training**\n",
    "\n",
    "30. What does the Trainer's `train()` method initiate in the fine-tuning process?\n",
    "    - **C) Fine-tuning the model on the dataset**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
